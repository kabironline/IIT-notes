# Unsupervised Learning
- Unsupervised Learning is a type of Machine Learning algorithm that learns patterns from unlabeled data.
- That data is mostly in form of $\{x_1, x_2, \dots, x_n\}$. Where $x_i \in \mathbb{R}^d$.
- Unsupervised Learning is also called as Descriptive Learning.
- Unsupervised Learning is used to find patterns in data. It is used to find structure in data. It is used to find hidden patterns in data.
- Unsupervised Learning is not a end itself it is a means to an end. It is used as a preprocessing step for Supervised Learning.
### Example : Clustering
- Clustering is a type of Unsupervised Learning algorithm that learns a function that maps an input to a discrete output based on example input-output pairs. It infers a function from unlabeled training data consisting of a set of training examples.
- For example clustering can be used to group similar customers together. It can be used to group similar products together. It can be used to group similar movies together.
## Dimensionality Reduction
- Dimensionality Reduction is a type of Unsupervised Learning algorithm that learns a function that maps an input to a discrete output based on example input-output pairs. It infers a function from unlabeled training data consisting of a set of training examples.
- For example dimensionality reduction can be used to reduce the number of features in a dataset. It can be used to reduce the number of dimensions in a dataset.
- Data : $x_1, x_2, \dots, x_n \in \mathbb{R}^d$
- Encoder $f : \mathbb{R}^d \rightarrow \mathbb{R}^{d'}$
- Decoder $g : \mathbb{R}^{d'} \rightarrow \mathbb{R}^d$
- Goal : $g(f(x_i)) \approx x_i$
- Loss : $\frac{1}{n}\sum_{i=1}^n ||g(f(x_i)) - x_i||^2$

## Density Estimation
- A density estimation algorithm estimates the probability density function of the underlying distribution of the data. It infers a function from unlabeled training data consisting of a set of training examples.
- Data : $x_1, x_2, \dots, x_n \in \mathbb{R}^d$
- Probability Mapping $P : \mathbb{R}^d \rightarrow \mathbb{R}$ that sums to $1$.
- Goal : $P(x_i)$ is large if $x \in \text{Data}$ is low
- Loss : $\frac{1}{n}\sum_{i=1}^n -\log(P(x_i))$