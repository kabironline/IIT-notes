# Choosing Prior Distribution
- Flat, uninformative
  - Nearly flat over the interval in which the parameter takes value
  - This usually reduces to something close to maximum likelihood
- Conjugate Priors
  - Pick a prior so that the posterior is in the same class as prior
  - Examples
    - Prior : Normal and Posterior : Normal
    - Prior : Beta and Posterior: Beta
- Inforamative priors
  - This needs some justification from the domain of the problem
  - Parameterize the prior so that its flatness can be controlled.
---
## Bernoulli$(p)$ samples with uniform prior
$$ X_1, X_2, \cdots, X_n \sim \text{Bernoulli}(\bold{p})$$
- Prior $\bold{p} \sim \text{Uniform }[0,1],$ continuous distribution
- Samples $x_1, \dots, x_n$
- Posterior $\bold{p}|(X_i=x_i)$ is continuous
  - Posterior density $\propto P(X_i=x_i|\bold{p}=p)f_{\bold{p}}(p)$
  - Posterior density $\propto p^w(1-p)^{n-w}, 0 \leq p \leq 1$
    - $w = \sum_{i=1}^n x_i$, number of successes
- Posterior Density : $\text{Beta}(w+1,n-w+1)$
  - Posterior Mean =  $\frac{w+1}{w+1+n-w+1} = \frac{w+1}{n+2} = \frac{x_1,\dots,x_n+1}{n+2}$
---
## Normal samples with unknown mean and known variance
$$X_1, \dots, X_n \sim \text{Normal}(M, \sigma^2)$$
- Prior $M \sim ~ \text{Normal}(\mu_0, \sigma_0^2)$, continuous distribution
  - $f_M(\mu) = \frac{1}{\sqrt{2\pi}\sigma_0}exp({-\frac{(\mu-\mu_0)^2}{2\sigma_0^2}})$
- Samples : $x_1, \dots, x_n$, Sample mean: $\bar{x} = (x_1 + \dots + x_n)/n$
- Posterior : $M|(X_i=x_i)$ is continuous
  - Posterior density $\propto P(X_i=x_i|M=\mu)f_M(\mu)$
  - Posterior density $\propto exp({-\frac{1}{2\sigma^2}\sum_{i=1}^n(x_i-\mu)^2})exp({-\frac{(\mu-\mu_0)^2}{2\sigma_0^2}})$
- Posterior density: Normal
  - Posterior mean = $\bar{x}\frac{n\sigma^2_0}{n\sigma^2_0+\sigma^2} + \mu_0\frac{\sigma^2}{n\sigma^2_0+\sigma^2}$
### Observation for Normal Prior
- Prior: Normal $(\mu_0, \sigma_0^2)$
  - How to pick $\mu_0$ and $\sigma_0$?
- Estimate is combination of data and prior
  - Prior is "updated" using data to get posterior
- If $n$ is very large, $\hat{\mu} \rightarrow$ sample mean
  - Data dominates the estimate
  - Prior plays no significant role
- If $n$ is small, prior contributes significantly to the estimate
  - Prior needs to have some justification when $n$ is small
- If variance of prior is large compared to variance of small, prior tends to be flat and uninformative.
  - Choice of variance of prior is important
