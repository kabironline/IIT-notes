# Estimation Error
### Defination
- $\theta:$ parameter, $\hat{\theta}(X_1,\dots,X_n)$ estimator
  - Error: $\hat{\theta}(X_1,\dots,X_n) - \theta$ is a random variable
- We expect the estimator random variable $\hat{\theta}(X_1,\dots, X_n)$ to take values around the actual value of the parameter $\theta$. So, the random varaible "Error" should be centered around 0.
### Example
- $X_1, X_2, \dots, X_n$ are $i.i.d. \ Binomial (p)$
- $\hat{p_1}= 1/2$, $\hat{p_2}= (X_1+X_2)/2$, $\hat{p_3}= \bar{X}/n$
- The variation of the error is different for different estimators
  - $\hat{p_1}$: does not work for all values of $p$
  - $\hat{p_2}$: varies a lot with the sample
  - $\hat{p_3}$: seems to be a good estimator
- We can use Chebyshev's inequality to quantify the variation of the error
- $$P(|\text{Error}| - E[\text{Error}]> \delta) \leq \frac{Var(\text{Error})}{\delta^2}$$
- Use the above bound
  - $$P(|\text{Error}|> p/10) \leq \frac{p(1-p)/n}{p^2/100}$$
- For any fixed $p$, the above probability tends to $0$ as $n$ tends to $\infty$
  - Chebyshev's bound results in fall of 1/$n$.
  - Using Chernoff bound

### Good Estimator
- $E[\text{Error}]$ should be close to or equal to $0$
- $Var(\text{Error})$ 