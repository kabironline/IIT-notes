# Independence of multiple random variables
### Defination
- Let $X_1, \dots, X_n$ be $n$ random variables defined in a probablity space with ranges $T_{X_1}, \dots, T_{X_n}$ respectively. $X_1, \dots, X_n$ are said to be independent if events defined using $X_i$ are mutually independent. Equivalently, $X_1, \dots, X_n$ are independent if and only if:
$$f_{X_1 \dots X_n}(t_1, \dots, t_n) = f_{X_1}(t_1) \cdot \dots \cdot f_{X_n}(t_n)$$
### Notes
- If $X$ and $Y$ are independent
  - Joint PMF equals product of marginal PMFs.
  - Conditional PMF equals marginal PMF.
- All subsets of independent random variables are independent.

### Example
- Tossing a fair coin thrice
  - Let $X_i = 1$ if the $i$th toss is a head, $0$ otherwise.
  - $X_i$ ~ $\text{Uniform}\lbrace 0,1 \rbrace$
# Independent and identically distributed (iid) random variables
### Defination
- Random variable $X_1,\dots, X_n$ are said to be independent and identically distributed (iid), if
  - They are independent.
  - The marginal PMFs are identical.