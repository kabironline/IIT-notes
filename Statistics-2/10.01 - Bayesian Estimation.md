# Bayesian estimation
- Bayesian estimation is a method of statistical inference in which Bayes' theorem is used to update the probability for a hypothesis as more evidence or information becomes available.
### Defination
$$ X_1,\dots ,X_n \sim i.i.d. X, \text{ parameter } \Theta $$
- $\Theta$ is a random variable
- Samples : $x_1,\dots ,x_n$
- According to Bayes' Rule : Posterior $\propto$ Likelihood $\times$ Prior
  $$ P(\Theta = \theta | S) = \frac{P(S|\Theta = \theta)P(\Theta = \theta)}{P(S)} $$
    - The normalization constant $P(S)$ does not depend on $\theta$
- Estimation using the posterior probability:
  - Posterior mode: $\hat{\theta} = \arg\max_\theta P(X|\Theta = \theta) f_\Theta(\theta)$
  - Posterior mean: $\hat{\theta} = E[\Theta|S]$, mean of posterior distribution
    - $(\Theta|S)$ may be a known distribution, and its mean might become a simple formula in some cases.
### Bayes' theorem
- We can use Bayes' theorem to calculate the probability of a hypothesis given our prior knowledge and the new information.
- Suppose
  $$X_1, X_n \sim Bernoulli(p)$$
- Suppose that $p \sim Uniform \{0.25, 0.75\}$
  - Assume $p$ is chosen first at random according to the above distribtution
  - Once $p$ is chosen, the samples are drawn according to the Bernoulli distribution with parameter $p$
- Samples are $1,0,1,1,0$
  - Estimating using Bayes' Rule
    - $P(p=0.25|S) = P(S|p=0.25)P(p=0.25)/P(S) = 0.25^3 \times 0.75^2 \times 0.5 / P(S) = 0.25$
    - $P(p=0.75|S) = 0.75^3 \times 0.25^2 \times 0.5 / P(S) = 0.75$
    - $P(S) = 0.25^3 \times 0.75^2 \times 0.5 + 0.75^3 \times 0.25^2 \times 0.5 = 0.25$
    - Using this we can calculate that $\hat{p}$ is $0.75$
  - Estimating using Posterior mean
    - $\hat{p} = 0.25P(p=0.25|S)+0.75P(p=0.75|S)=0.625$
