# Normal Samples
$$ X_1, X_2, ..., X_n \sim i.i.d. \text{Normal}(\mu, \sigma^2)$$
- Very common assumption in many situations
  - CLT is used as justification
- Sample Mean
 $$ \bar{X} = \frac{X_1 + \dots + X_n}{n}$$
- Sample Variance
$$ S^2 = \frac{(X_1 - \bar{X})^2 + \dots (X_n - \bar{X})^2}{n-1}$$

# Distribution of Sample Mean
- $X_1, X_2, ..., X_n \sim i.i.d. \text{Normal}(\mu, \sigma^2)$
- $\bar{X} = \frac{X_1 + \dots + X_n}{n}$
- Sample mean is a linear combination of $i.i.d.$ normal random variables
  - So, Sample mean has a normal distribution
  - $$\bar{X} \sim \text{Normal}(\mu, \frac{\sigma^2}{n})$$
- $E(\bar{X}) = \mu$
- $Var(\bar{X}) = \frac{\sigma^2}{n}$

# Sum of squares of Normal Samples: Chi-Square Distribution
$$ X_1, X_2, ..., X_n \sim i.i.d. \text{Normal}(0 \sigma^2)$$
- $X_i^2$ : Gamma $(\frac{1}{2}, \frac{1}{2\sigma^2})$ independent
- Sum of $n$ independent Gamma$(\alpha, \beta)$ is Gamma$(n\alpha, \beta)$
- $$ \sum_{i=1}^n X_i^2 \sim \text{Gamma}(\frac{n}{2}, \frac{1}{2\sigma^2})$$
- Gamma distribution with $\alpha = \frac{n}{2}$ and $\beta = \frac{1}{2\sigma^2}$ is called Chi-Square distribution with $n$ degrees of freedom
### Theorem
- Suppose $X_1, X_2, ..., X_n \sim i.i.d. \text{Normal}(\mu, \sigma^2)$
  - $\bar{X} \sim Normal(\mu, \sigma^2/n)$
  - $\frac{(n-1)S^2}{\sigma^2} \sim \chi^2_{n-1}$
  - $\bar{X}$ and $S^2$ are independent
- For normal samples, the joint distribution of sample mean and variance is perfectly known